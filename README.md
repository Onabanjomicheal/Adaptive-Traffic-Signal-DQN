# ğŸš¦ Lagos Traffic Optimization with Deep Q-Networks (DQN) in SUMO

![Isolo-Egbe Map](https://raw.githubusercontent.com/Onabanjomicheal/Adaptive-Traffic-Signal-DQN/main/isolo_egbe.png)

A Reinforcement Learning model that clears traffic in Lagos 59% faster than traditional systemsâ€”tested on real maps using SUMO and Deep Q-Networks.

## ğŸ”¥ Why This Matters
Lagos traffic isnâ€™t just inconvenientâ€”itâ€™s catastrophic. The Oke Afa Roundabout and Isoloâ€“Mushin Corridor are among the city's most congested intersections. Traditional fixed-timing systems collapse under pressure. This project uses Deep Reinforcement Learning to fix that.

Our DQN-based signal controller outperforms traditional systems, cutting travel time by over 30%, increasing speed by 50%, and completing nearly 2x more tripsâ€”all in a realistic SUMO simulation built from actual OSM map data.

## Table of Contents

- [Project Goals](#project_goals)
- [Agents Built](#agents_built)
- [How It Was Tested](#how_it_was_tested)
- [Agents Implemented](#agents-implemented)
- [Performance Highlights](#performance_highlights)
- [Demo Video](#demo_video)
- [Stack and Tools](#stack_tools)
- [Contributing](#contributing)
- [What to Do Next](#what_to_do_next)
- [Author](#author)

## ğŸ¯ Project Goals
- Simulate Lagos traffic at key intersections (Oke Afa Roundabout, Isoloâ€“Mushin) using SUMO.

- Train a Deep Q-Network agent to dynamically adapt traffic signals in real-time.

- Benchmark against Fixed-Time and classical Q-Learning agents.

- Measure speed, throughput, emissions, and travel efficiency.

## ğŸ§  Agents Built

| Agent                  | Description                                                                      |
| ---------------------- | -------------------------------------------------------------------------------- |
| âœ… **DQN Agent**        | Learns traffic light timing via neural networks. Maximizes flow, minimizes wait. |
| â¬œ **Q-Learning Agent** | Table-based RL. Simple but effective baseline.                                   |
| âŒ **Fixed-Time Agent** | Static signal schedule. Old-school, non-adaptive benchmark.                      |


## ğŸ§ª How It Was Tested
- SUMO simulation (command-line, 0.5s step size).

- 3,600s runs for Fixed and QL. DQN terminated early due to full network clearance.

- Output data:

Trip info

Emissions (CO2, CO, HC, NOx, PMx, Fuel, Noise)

Speed, queue length, and travel time

Visuals and reports generated with Matplotlib, Excel, and Pandas.

## ğŸ“Š Performance Highlights

| Metric               | Fixed Timing | Q-Learning | DQN            |
| -------------------- | ------------ | ---------- | -------------- |
| **Trips Completed**  | 1290         | 1519       | **2401** âœ…     |
| **Avg. Travel Time** | 550s         | 408s       | **361s** âœ…     |
| **Avg. Speed**       | 4.15 m/s     | 5.21 m/s   | **6.31 m/s** âœ… |
| **Simulation Time**  | 3600s        | 3600s      | **1446s** âœ…    |

DQN cleared all vehicles in under 25 minutes, while others needed a full hourâ€”and still didnâ€™t finish.

ğŸ“ See full breakdown in results/Traffic metrics report.xlsx

## ğŸ“½ï¸ Demo Video
ğŸš§ (To be added â€” consider recording QL or OSM sim)

Embed the video here once it's ready: .gif, .mp4, or YouTube iframe. Show it in action.
A basic reinforcement learning agent that uses a Q-table to store and update Q-values. While less scalable than DQN for large state spaces, it provides a valuable comparison for the learning process.

## ğŸ§° Stack and Tools
SUMO / NetEdit (network creation and traffic simulation)

Python: Core logic

TensorFlow + Keras (DQN Model)

SumoLib, Traci (interface with SUMO)

Pandas, Numpy, Matplotlib (data analysis and plotting)


## ğŸ¤ Contributing
Got a better RL architecture? Want to simulate a new intersection in Lagos or Nairobi?
PRs and issues welcome.

## âœ… What to Do Next
Clone and run the sim.

Watch the demo (coming soon).

Try your own reward function.

Open an issue. Let's scale this.

## ğŸ‘¨â€ğŸ’» Author
- Onabanjo Micheal
- Passionate about AI for sustainable cities.
- ğŸ“« Connect on LinkedIn
